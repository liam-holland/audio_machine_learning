{
 "cells": [
  {
   "cell_type": "code",
   "id": "0f963d2a-f7c4-4ddc-b47a-958e4a7b8a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T14:49:37.284097Z",
     "start_time": "2026-02-12T14:49:36.367241Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7673dee0-e1c4-435b-9426-631f66b4ba2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T14:49:37.345889500Z",
     "start_time": "2026-02-12T14:49:37.292076700Z"
    }
   },
   "source": [
    "def sigmoid(z_):\n",
    "    return 1/(1 + np.exp(-z_))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "2662925e-d0cc-44f1-9e9f-97618ca0a61c",
   "metadata": {},
   "source": [
    "# Audio Machine Learning - Formative Task - Exercise 2\n",
    "## 1 - Binary Classification with Logistic Regression Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12956d-904f-4593-95ae-b8e32ed4a8ce",
   "metadata": {},
   "source": [
    "### 1.1 - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3316761-fe81-4d32-8a9d-747da0e937f6",
   "metadata": {},
   "source": [
    "The dataset $D = \\{(x^{(i)}, y^{(i)})\\}^N_{i=1}$, contains $N$ labelled datapoints. Each datapoint consists of a feature vector, $x^{(i)}$, and the correspoinding class label, $y^{(i)}$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c209c4b2-ef51-4eb0-aa68-ef264ea91e71",
   "metadata": {},
   "source": [
    "$x^{(i)}$ denotes the feature vector of the $i$-th datapoint is the dataset, and $y^{(i)}$ denotes the $i$-th label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62831b34-2323-4281-9a64-17ead44ab43b",
   "metadata": {},
   "source": [
    "Each feature vector $x^{(i)}$, consists of $j$ features. $x^{(i)}_j$ denotes the $j$-th element in the feature vector $x^{(i)}$.\\\n",
    "The first element of the feature vector, $x^{(i)}_0$, is the 'dummy variable', which is always equal to one.\n",
    "\n",
    "Each class label, $y^{(i)}$, consists of a single class label. Each class label is either 1 or 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a329c-53a9-48d4-817d-3dd6f74d61a9",
   "metadata": {},
   "source": [
    "### 1.2 - Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a6dd9-06fd-421e-bbc0-61a8f287f862",
   "metadata": {},
   "source": [
    "The logistic regression model is a parameterised classification model. It has $j$ parameters, one for each feature in the feature vector $x^{(i)}$. The parameters are held in the parameter vector $\\theta$, where $\\theta_j$ denotes the $j$-th parameter.\n",
    "\n",
    "Assuming that $\\theta$ and $x^{(i)}$ are both $j \\times 1$  matrices (also known as column vectors), the output of the logistic regression model for the $i$-th item in the dataset D is given by:\n",
    "\n",
    "$$f(x^{(i)}, \\theta) = \\frac{1}{1 + e^{-\\theta^Tx^{(i)}}} = \\hat{y}^{(i)}$$\n",
    "\n",
    "Where $\\hat{y}^{(i)}$ the model's prediction for $i$-th datapoint in the dataset D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d2cf0-715d-432a-93be-03ca2a89ec73",
   "metadata": {},
   "source": [
    "### 1.3 - Binary Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d8b19-7a8c-4585-85e3-77cba80fe56d",
   "metadata": {},
   "source": [
    "The binary cross entropy loss function measures the difference between the logistic regression model's prediction, $\\hat{y}^{(i)}$, and the true class label, $y^{(i)}$.\n",
    "\n",
    "It is given by the following formula:\n",
    "\n",
    "$$L(y^{(i)},\\hat{y}^{(i)})=-(y^{(i)}\\log(\\hat{y}^{(i)}) + (1 - y^{(i)})\\log(1 - \\hat{y}^{(i)}))$$\n",
    "\n",
    "Where log is the natural logarithm function, given in numpy by np.log()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c602c5-2afb-4df0-9721-e5211857ca8f",
   "metadata": {},
   "source": [
    "The derivative of the loss function with respect to the parameter $\\theta_j$, for a single datapoint $i$, is given by:\n",
    "\n",
    "$$\\frac{\\delta}{\\delta\\theta_j}L(\\theta) = -(y^{(i)} - \\hat{y}^{(i)})x^{(i)}_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0b4b8-34a0-427f-95a5-4ce569c8b8df",
   "metadata": {},
   "source": [
    "### 1.4 - Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21157ab-412a-4350-9ae3-5e1db29f652d",
   "metadata": {},
   "source": [
    "Gradient descent is performed by iteratively updating each of the parameters in parameter vector $\\theta$. For each iteration, the gradient of the loss with respect to each of the parameters is found, and the each parameter is updated according to the following:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha(-(y^{(i)} - \\hat{y}^{(i)})x^{(i)}_j)$$\n",
    "\n",
    "Where $\\alpha$ is a small constant called the 'Learning Rate'. This gives the gradient descent update rule for a single example $i$. To carry out batch gradient descent, for each iteration we take the sum of the gradient of the loss function with respect to $\\theta_j$, over each of the $N$ examples in the dataset $D$.\n",
    "\n",
    "$$\\theta_j := \\theta_j -  \\frac{\\alpha}{N}\\sum_{i=1}^{N} (-(y^{(i)} - \\hat{y}^{(i)})x^{(i)}_j)$$\n",
    "\n",
    "This calculates the gradient of the loss function with respect to $\\theta_j$, and then updates $\\theta_j$ by taking a step in the direction of the negative of the gradient. Iteratively repeating this process causes the loss to decrease, until is converges on the global minimum (if the learning rate is set appropriately).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a40b7-fab1-480f-afd5-4635981793fe",
   "metadata": {},
   "source": [
    "## 2 - Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c0e6be-451c-4dd8-8110-8dc8f53770ce",
   "metadata": {},
   "source": [
    "### 2.1 - Task 1 - Implementing the Logistic Regression model with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412994d-ae21-4819-831a-668fa4913139",
   "metadata": {},
   "source": [
    "Your task is to implement the logistic regression model. It should work for a dataset with any number of training examples, $N$, and any number of features $j$. You should used the Python class template provided below:"
   ]
  },
  {
   "cell_type": "code",
   "id": "31b8eb20-a348-4cff-a078-670aaf30440c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:18:52.473424600Z",
     "start_time": "2026-02-12T16:18:52.441893300Z"
    }
   },
   "source": [
    "# define the LogisticRegression class\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "   #  The LogisticRegression class should have the method 'load_dataset', which takes the features and \n",
    "   #  corresponding labels as it's argument and saves it for training.\n",
    "   #  The 'load_dataset' method should do the following:\n",
    "   #       1. Initialise the model's parameters, as self.thetas, where self.thetas is a numpy array of \n",
    "   #          zeros containing the appropriate number of parameters based on the 'Dataset' argument \n",
    "   #          provided to the model (ensure that self.thetas.dtype is 'float' and not 'int')\n",
    "   #       2. Save the maximum and minimum values of each feature contained in the dataset as class \n",
    "   #          attributes using 'self.'\n",
    "   #       3. Normalise the features in 'Dataset', using min-max normalisation so they have a minimum \n",
    "   #          value of 0 and maximum value of 1\n",
    "   #          # You don't need to normalise the 'dummy variable' x_0\n",
    "   #       4. Add the dummy variable to the features array. The dummy variable should have N elements, \n",
    "   #          which are all equal to 1.\n",
    "   #       5. Save the features and labels to the class using self.features = features_ and self.labels = labels_\n",
    "   #  If the LogisticRegression class already has a dataset saved, it should be replaced by whatever dataset is \n",
    "   #  passed to the 'load_dataset' method.\n",
    "\n",
    "\n",
    "    # The argument 'features_' should be a numpy array of shape (N, j), \n",
    "    # The argument 'labels_' should be a numpy array of shape (N)\n",
    "    def load_dataset(self, features_, labels_):\n",
    "        \"\"\" \n",
    "        \n",
    "        Args:\n",
    "            features_(np.array): Feature array with shape (N x j)\n",
    "            labels_(np.array): Label array with shape (N)\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            None\n",
    "\n",
    "        \"\"\"\n",
    "               \n",
    "        self.features = np.array(features_)\n",
    "        self.labels = np.array(labels_).reshape( np.shape(self.features)[0] , 1 )\n",
    "        dimFeatures = np.ndim(self.features)\n",
    "\n",
    "        # Get max and min for each feature\n",
    "        self.max_feature = np.max(self.features, axis= 0)\n",
    "        self.min_feature = np.min(self.features, axis= 0)\n",
    "  \n",
    "        self.norm_features = (self.features - self.min_feature) / (self.max_feature - self.min_feature)\n",
    "  \n",
    "        # Insert a column of ones\n",
    "        self.norm_features = np.insert(self.norm_features , 0 , 1 , axis= 1)\n",
    "\n",
    "        self.features_number = np.shape(self.norm_features)[1]\n",
    "\n",
    "        self.thetas = np.zeros((self.features_number , 1))\n",
    "\n",
    "        if dimFeatures != 2:\n",
    "            raise ValueError( f\"Expected 2D array (N, j), got a {features_.ndim}D array\")\n",
    "        \n",
    "        if self.features.shape[0] != self.labels.shape[0]:\n",
    "            raise ValueError( f\"Features and labels must have the same number of rows\")\n",
    "        \n",
    "        return self\n",
    "   \n",
    "\n",
    "    \n",
    "   #  The 'train_model' method implements batch gradient descent. The argument 'iters' determines how many steps of\n",
    "   #  batch gradient descent to carry out. For each training iteration, this function should do the following:\n",
    "   #       1. Calculate the model's predictions with the current model parameters, using the formula given in section 1.2\n",
    "   #       2. Calculate and save the binary cross entropy loss for the current model parameters\n",
    "   #          # Be aware that large negative numbers might be rounded down to 0 by the sigmoid function. \n",
    "   #          # This will result in np.log(0) returning -infinity.\n",
    "   #          # You can limit the range of possible input values to the sigmoid function using np.clip()\n",
    "   #       3. Update each model parameter according to the batch gradient descent rule defined in section 1.4\n",
    "   #  After completing all iterations, the method should return a list of the losses\n",
    "    \n",
    "   #  The argument 'alpha' determines the step size\n",
    "   #  Note that the sigmoid function is defined at the start of this notebook\n",
    "\n",
    "\n",
    "    def train_model(self, iters_, alpha_):\n",
    "        \n",
    "        self.alpha = alpha_\n",
    "        self.iters = iters_\n",
    "        self.loss_history = np.zeros([self.iters,1])\n",
    "\n",
    "        for i in range(self.iters):\n",
    "\n",
    "            # Need thetas to be a 1 x J and features to be a J x N\n",
    "            z = self.norm_features @ self.thetas\n",
    "\n",
    "            y_hat = 1 / ( 1 + np.exp( -z ) )\n",
    "\n",
    "            y_hat = np.clip(y_hat, 1e-15, 1 - 1e-15)\n",
    "\n",
    "            loss = -( self.labels *  np.log(y_hat) + (1 - self.labels) * np.log(1 - y_hat))\n",
    "\n",
    "            self.loss_history[i] = np.mean( loss )\n",
    "\n",
    "            grad_loss = -( self.labels - y_hat ) * self.norm_features\n",
    "\n",
    "            self.thetas = self.thetas - self.alpha * np.mean( grad_loss , axis = 0).reshape(self.features_number,1)\n",
    "\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "   #  The 'predict' method take a matrix of features as its argument. It should then apply the logistic regression\n",
    "   #  model to the input features to produce the model's predicitions. Be sure to normalise the features, using the\n",
    "   #  self.feat_min and self.feat_max attributes saved by the 'load_dataset' method\n",
    "   #  Apply the decision boundary, such that:\n",
    "   #      - predictions greater than 0.5 belong to the class '1' \n",
    "   #      - predictions less than 0.5 belong to the class '0'\n",
    "   #  The method should then return the predicted class labels\n",
    "\n",
    "\n",
    "    # # The argument 'features_' should be a numpy array of shape (N, j) where N is the number of examples to be classified.\n",
    "    def predict(self, features_):\n",
    "\n",
    "        pred_features = np.array(features_)\n",
    "        pred_dimFeatures = np.ndim(pred_features)\n",
    "\n",
    "        pred_norm_features = (pred_features - self.min_feature) / (self.max_feature - self.min_feature)\n",
    "\n",
    "        # Insert a column of ones\n",
    "        pred_norm_features = np.insert(pred_norm_features , 0 , 1 , axis= 1)\n",
    "\n",
    "        if pred_dimFeatures != 2:\n",
    "            raise ValueError( f\"Expected 2D array (N, j), got {features_.ndim}\")\n",
    "        \n",
    "        z = pred_norm_features @ self.thetas\n",
    "        \n",
    "        self.y_hat_pred = 1 / ( 1 + np.exp( -z ) )\n",
    "\n",
    "        self.predictions = np.where(self.y_hat_pred >= 0.5, 1, 0)\n",
    "\n",
    "        return self.predictions"
   ],
   "outputs": [],
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "id": "77fe16bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:19:40.141752Z",
     "start_time": "2026-02-12T16:19:40.117237Z"
    }
   },
   "source": [
    "# feat = np.array([ [1,2] , [2,1] , [2,4] ])\n",
    "# labels = np.array([[1], [0] , [1]])\n",
    "#\n",
    "# np.shape(feat)\n",
    "# np.shape(labels)\n",
    "#\n",
    "# Model = LogisticRegression()\n",
    "#\n",
    "# load = Model.load_dataset(feat , labels)\n",
    "#\n",
    "# train = Model.train_model(10, 0.001)\n",
    "#\n",
    "# predict = Model.predict(feat)\n",
    "#\n",
    "# print(\"Help\")\n"
   ],
   "outputs": [],
   "execution_count": 149
  },
  {
   "cell_type": "markdown",
   "id": "e18a98a9-01ad-4ed0-b06b-96e15bcc2b1f",
   "metadata": {},
   "source": [
    "## 3 - Training the Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2484c1-1e9a-4cdb-95d0-0c8dadabff73",
   "metadata": {},
   "source": [
    "## 3.1 - Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97265a2-c683-4cbf-af01-c9e576db38fd",
   "metadata": {},
   "source": [
    "The below code loads the dataset, and splits it into a training and test dataset.\\\n",
    "You shouldn't change the below code, just run it to load the dataset (make sure 'RoomsDataset.csv' is in the same directory as this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "id": "5131faf3-530c-4341-b67c-6105e372e6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:19:41.448699100Z",
     "start_time": "2026-02-12T16:19:41.436178400Z"
    }
   },
   "source": [
    "Dataset = pd.read_csv('RoomsDataset.csv', index_col=False)\n",
    "features = Dataset.iloc[:,0:2].values\n",
    "labels = Dataset.iloc[:,2:].values\n",
    "labels = labels.squeeze() # Squeeze the labels to be shape (N,)\n",
    "Train_Dataset = (features[0:180,:], labels[0:180])\n",
    "Test_Dataset = (features[180:,:], labels[180:])"
   ],
   "outputs": [],
   "execution_count": 150
  },
  {
   "cell_type": "markdown",
   "id": "149aadcb-fd50-4cb7-b024-e3a4e09b7791",
   "metadata": {},
   "source": [
    "The below code creates an instance of the class LogisticRegression(), loads the Train_Dataset and trains the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "965f5424-3479-498e-9c9e-73027e798f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:19:43.384357200Z",
     "start_time": "2026-02-12T16:19:42.246659Z"
    }
   },
   "source": [
    "Model = LogisticRegression()\n",
    "Model.load_dataset(Train_Dataset[0], Train_Dataset[1].reshape(180,1))\n",
    "losses = Model.train_model(20000, 0.2)"
   ],
   "outputs": [],
   "execution_count": 151
  },
  {
   "cell_type": "markdown",
   "id": "6274221a-7fc2-466e-900f-099e7bc5b743",
   "metadata": {},
   "source": [
    "This plots the loss values over the duration of training. If everything is implemented correctly it should look like the graph in the file 'LogRegTraining.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "id": "c67c8cd7-1e95-4cbb-84f6-cba2e53a532f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:19:44.194830300Z",
     "start_time": "2026-02-12T16:19:44.023276700Z"
    }
   },
   "source": [
    "plt.plot(losses.loss_history)\n",
    "plt.xlabel('Training iteration')\n",
    "plt.ylabel('BCE Loss')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'BCE Loss')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 152
  },
  {
   "cell_type": "markdown",
   "id": "a2760018-455d-4959-93f5-30d8153bccb5",
   "metadata": {},
   "source": [
    "The below code should apply your trained model to the Test_Dataset, and return the predicted classes. If the training appeared to work (achieving a loss of about 0.16 by the final iteration), but the predictions are very wrong, make sure that you've applied the normalisation correctly to the Test_Dataset features before running prediction."
   ]
  },
  {
   "cell_type": "code",
   "id": "0d0ea5e9-5875-4b06-a2f3-daaca848b383",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:08:28.418497200Z",
     "start_time": "2026-02-12T16:08:28.408472200Z"
    }
   },
   "source": [
    "predictions = Model.predict(Test_Dataset[0])\n",
    "true_labels = Test_Dataset[1]"
   ],
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:08:29.438026200Z",
     "start_time": "2026-02-12T16:08:29.418119800Z"
    }
   },
   "cell_type": "code",
   "source": "Model.predictions\n",
   "id": "d86dc8776f4725a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "cell_type": "markdown",
   "id": "4421d221-0f8c-4016-884e-82b4a33273c5",
   "metadata": {},
   "source": [
    "## 3.2 - Task 2 - Testing the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e0a8d-db46-4b1c-a1bd-e7fb018f372f",
   "metadata": {},
   "source": [
    "Compare the predictions to the true class labels from 'Test_Dataset'. \n",
    "The accuracy is given by the ratio of the number of correct predictions to the total number of samples input to the classifier.\n",
    "Calculate the accuracy of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "id": "10ef0880-35f4-4de0-8442-e69577a3d9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:21:43.823387900Z",
     "start_time": "2026-02-12T16:21:40.009409800Z"
    }
   },
   "source": "true_labels = true_labels.reshape(20,1)",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:25:36.936048600Z",
     "start_time": "2026-02-12T16:25:36.904372400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "matches = (predictions == true_labels)\n",
    "\n",
    "accuracy = np.sum(matches) / np.size(predictions, axis = 0)\n",
    "\n"
   ],
   "id": "3924168504a068f3",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-12T16:34:35.730987200Z",
     "start_time": "2026-02-12T16:34:32.275896400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "true_positives = np.logical_and( predictions == 1, true_labels == 1)\n",
    "false_positives = np.logical_and( predictions == 1, true_labels == 0)\n",
    "false_negative = np.logical_and( predictions == 1, true_labels == 0)\n",
    "true_negative = np.logical_and( predictions == 0, true_labels == 0)\n",
    "\n"
   ],
   "id": "38c2f2a3445b1d4d",
   "outputs": [],
   "execution_count": 159
  },
  {
   "cell_type": "markdown",
   "id": "0a0e05bf-f32d-4d40-882f-0a30a0bb6083",
   "metadata": {},
   "source": [
    "For the below:\\\n",
    "a True Positive is a case where the model prediction $\\hat{y}$ = 1 and the label $y$ = 1\\\n",
    "a False Positive is a case where the model prediction $\\hat{y}$ = 1 and the label $y$ = 0\\\n",
    "a False Negative is a case where the model prediction $\\hat{y}$ = 0 and the label $y$ = 1\\\n",
    "a True Negative is a case where the model prediction $\\hat{y}$ = 0 and the label $y$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5d7c9-28ca-4635-9ad3-74b27e6beffb",
   "metadata": {},
   "source": [
    "The True Postive Rate is given by the ratio of True Positives to the total number of actual positives (True Positives + False Negatives). Considering label y=1 to be a positive case, calculate the True Postive Rate rate of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "id": "69321a8f-d1ea-477c-ad69-5dce94e7b59a",
   "metadata": {},
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c6c81e85-b0d0-4831-bf54-d00aa9fbd3f3",
   "metadata": {},
   "source": [
    "The False Positive Rate is given by the ratio of False Positives to the total number of negatives (False Positives + True Negatives). Calculate the False Positive Rate for this classifier."
   ]
  },
  {
   "cell_type": "code",
   "id": "614d9002-964d-4bad-8962-1ac232b7bfc9",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2fd677a-02bd-42ac-8e8b-9fb2ab35fc8b",
   "metadata": {},
   "source": [
    "The True Negative Rate is given by the ratio of True Negatives to the total number of negatives (True Negatives + False Positives). Calculate the True Negative Rate for this classifier."
   ]
  },
  {
   "cell_type": "code",
   "id": "706dc04a-cb60-43ee-8061-3a3ea71508cf",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
